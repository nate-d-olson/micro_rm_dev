{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Whole genome vcf files\n",
    "\n",
    "Input: Individually mapped bam files     \n",
    "Output: Single VCF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import subprocess\n",
    "from bwa_mem_pe import *\n",
    "from consensus_base_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_run_params(run_info,parameters):\n",
    "    # hash for storing run specific information\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    run_params = defaultdict(str)\n",
    "    run_info_list = run_info.split(\":\")\n",
    "    run_params['plat'] = run_info_list[1]\n",
    "    run_params['run_id'] = run_info_list[0]        \n",
    "    run_params['out_dir'] = parameters['root_dir'] + parameters['analysis_out_dir']\n",
    "    run_params['log_dir'] = run_params['out_dir'] + \"logs\"\n",
    "    bam_root = parameters['root_dir'] + parameters['analysis_out_dir'] + \"tmp/\" + run_params['run_id']\n",
    "    run_params['bam'] = parameters['root_dir'] + parameters['bam_dir'] + \"/\" + \\\n",
    "                        run_params['run_id'] + \".bam\"\n",
    "    run_params['fix_file'] = bam_root + \"_fix.bam\"\n",
    "    run_params['sort_file'] = bam_root + \"_sort.bam\"\n",
    "    run_params['group_sort_file'] = bam_root + \"_group_sort.bam\"\n",
    "    run_params['realign_file'] = bam_root + \"_realign.bam\"\n",
    "    run_params['intervals_file'] = bam_root + \".intervals\"\n",
    "    run_params['markdup_file'] = bam_root + \"_markdup.bam\"\n",
    "    run_params['metrics_file'] = bam_root + \".metrics\"\n",
    "    return run_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dedup_realign_single_bam(bam_params, consensus_params):\n",
    "    ''' Processing single bam file'''\n",
    "    bam_group_sort(in_bam = bam_params['bam'], \n",
    "                   out_bam = bam_params['group_sort_file'], \n",
    "                   log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_fixmate(in_bam = bam_params['group_sort_file'],\n",
    "                out_bam = bam_params['fix_file'],\n",
    "                log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_sort(in_bam = bam_params['fix_file'], \n",
    "            out_sort = bam_params['sort_file'], \n",
    "            out_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_index(bam = bam_params['sort_file'],\n",
    "              out_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_realign(ref = consensus_params['ref'],\n",
    "                in_bam = bam_params['sort_file'],\n",
    "                out_bam = bam_params['realign_file'], \n",
    "                intervals_file = bam_params['intervals_file'],\n",
    "                log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_markdup(in_bam = bam_params['realign_file'], \n",
    "                out_bam = bam_params['markdup_file'], \n",
    "                metrics_file = bam_params['metrics_file'],\n",
    "                log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_index(bam = bam_params['markdup_file'],\n",
    "              out_dir = bam_params['log_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_consensus_base_pipeline(run_params,consensus_params):\n",
    "    \n",
    "    ## creating file with run parameters\n",
    "    run_log_file = open(run_params['out_dir']+\"/\" + run_params['run_id'] +\"-run_parameters.txt\", 'w')\n",
    "    run_log_file.write(\"Parameter\\tValue\\n\")\n",
    "    for i in run_params.keys():\n",
    "        run_log_file.write(\"%s\\t%s\\n\" % (i, run_params[i]))\n",
    "    for i in consensus_params.keys():\n",
    "        run_log_file.write(\"%s\\t%s\\n\" % (i, consensus_params[i]))\n",
    "    run_log_file.close()\n",
    "    \n",
    "    ## processing bam\n",
    "    dedup_realign_single_bam(run_params, consensus_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def genome_pileups(parameters, markdup_files):\n",
    "    \n",
    "    out_dir = parameters['root_dir'] + parameters['analysis_out_dir']\n",
    "    vcf_file = out_dir + \"/\" + \"RM8375-MiSeq.vcf\"\n",
    "    \n",
    "    genome_calls_mpileup(markdup_files['MiSeq'],parameters['ref'],vcf_file,out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dat(filename):\n",
    "    #process input file with configuration information\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    parameters = defaultdict(str)\n",
    "    with open(filename,'r') as f:\n",
    "        for line in f:\n",
    "            param = line.strip().split(\"=\")\n",
    "            parameters[param[0]] = param[1]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(filename):\n",
    "    #read run parameters from input file and process using pathoscope\n",
    "    parameters = read_dat(filename)\n",
    "    \n",
    "    # creating temp and log directories\n",
    "    subprocess.call(['mkdir','-p',parameters['root_dir']+ parameters['analysis_out_dir']+\"/tmp/\"])\n",
    "    subprocess.call(['mkdir','-p',parameters['root_dir']+ parameters['analysis_out_dir']+\"/logs/\"])\n",
    "    \n",
    "    \n",
    "    # list of refined bams\n",
    "    markdup_files = {'PGM':[], 'MiSeq':[]}\n",
    "    for i in parameters['datasets'].split(\";\"):\n",
    "        run_params = define_run_params(i,parameters)\n",
    "    \n",
    "        markdup_files[run_params['plat']] += run_params['markdup_file']\n",
    "            \n",
    "        run_consensus_base_pipeline(run_params, parameters)\n",
    "       \n",
    "    # pileups by platform\n",
    "    genome_pileups(parameters, markdup_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting bam ...\n",
      "Fixing mate pairs ...\n",
      "Realignment Around Indels ...\n",
      "Marking Duplicates ...\n",
      "Sorting bam ...\n",
      "Fixing mate pairs ..."
     ]
    }
   ],
   "source": [
    "main(\"consensus_base_params_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* clean up input definitions\n",
    "* output directory \n",
    "    run_name - root directory\n",
    "    \\tmp - intermediate files\n",
    "    \\run_id\n",
    "        | final bam\n",
    "        \\ logs - log files\n",
    "    \\vcf - platform specific vcf files\n",
    "    \n",
    "* need reference dict file - create function, seperate python file with scripts for indexing and creating dict for the reference\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_purity/:\r\n",
      "total 8.0K\r\n",
      "drwxr-xr-x 1 1000 staff 952 Jan 13  2015 \u001b[0m\u001b[01;34mlogs\u001b[0m/\r\n",
      "-rw-r--r-- 1 1000 staff 924 Jan 13  2015 SRR1555296-run_parameters.txt\r\n",
      "-rw-r--r-- 1 1000 staff 924 Jan 13  2015 SRR1555297-run_parameters.txt\r\n",
      "drwxr-xr-x 1 1000 staff 340 Jan 13  2015 \u001b[01;34mtmp\u001b[0m/\r\n",
      "\r\n",
      "sequence_purity/logs:\r\n",
      "total 48K\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_fixmate-2014-12-07-17-42-56.log\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_fixmate-2014-12-07-17-42-56.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_fixmate-2014-12-07-17-46-07.log\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_fixmate-2014-12-07-17-46-07.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_group_sort-2014-12-07-17-41-42.log\r\n",
      "-rw-r--r-- 1 1000 staff   40 Jan 13  2015 bwa_group_sort-2014-12-07-17-41-42.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_group_sort-2014-12-07-17-45-04.log\r\n",
      "-rw-r--r-- 1 1000 staff   40 Jan 13  2015 bwa_group_sort-2014-12-07-17-45-04.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-44-44.log\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-44-44.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-45-04.log\r\n",
      "-rw-r--r-- 1 1000 staff   92 Jan 13  2015 bwa_index-2014-12-07-17-45-04.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-47-39.log\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-47-39.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-47-54.log\r\n",
      "-rw-r--r-- 1 1000 staff   92 Jan 13  2015 bwa_index-2014-12-07-17-47-54.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_markdup-2014-12-07-17-45-04.log\r\n",
      "-rw-r--r-- 1 1000 staff 1.6K Jan 13  2015 bwa_markdup-2014-12-07-17-45-04.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_markdup-2014-12-07-17-47-54.log\r\n",
      "-rw-r--r-- 1 1000 staff 1.6K Jan 13  2015 bwa_markdup-2014-12-07-17-47-54.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_realign-2014-12-07-17-44-52.log\r\n",
      "-rw-r--r-- 1 1000 staff 7.1K Jan 13  2015 bwa_realign-2014-12-07-17-44-52.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_realign-2014-12-07-17-47-46.log\r\n",
      "-rw-r--r-- 1 1000 staff 7.1K Jan 13  2015 bwa_realign-2014-12-07-17-47-46.stder\r\n",
      "-rw-r--r-- 1 1000 staff   40 Jan 13  2015 bwa_sort-2014-12-07-17-43-44.stder\r\n",
      "-rw-r--r-- 1 1000 staff   40 Jan 13  2015 bwa_sort-2014-12-07-17-46-48.stder\r\n",
      "\r\n",
      "sequence_purity/tmp:\r\n",
      "total 1.4G\r\n",
      "-rw-r--r-- 1 1000 staff 273M Jan 13  2015 SRR1555296_fix.bam\r\n",
      "-rw-r--r-- 1 1000 staff 273M Jan 13  2015 SRR1555296_group_sort.bam\r\n",
      "-rw-r--r-- 1 1000 staff 193M Jan 13  2015 SRR1555296_sort.bam\r\n",
      "-rw-r--r-- 1 1000 staff  17K Jan 13  2015 SRR1555296_sort.bam.bai\r\n",
      "-rw-r--r-- 1 1000 staff 229M Jan 13  2015 SRR1555297_fix.bam\r\n",
      "-rw-r--r-- 1 1000 staff 229M Jan 13  2015 SRR1555297_group_sort.bam\r\n",
      "-rw-r--r-- 1 1000 staff 161M Jan 13  2015 SRR1555297_sort.bam\r\n",
      "-rw-r--r-- 1 1000 staff  17K Jan 13  2015 SRR1555297_sort.bam.bai\r\n"
     ]
    }
   ],
   "source": [
    "ls -lRh sequence_purity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm -r sequence_purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Sun Dec 07 20:58:43 UTC 2014] net.sf.picard.sam.CreateSequenceDictionary REFERENCE=../data/RM8375/ref/CFSAN008157.HGAP.fasta OUTPUT=../data/RM8375/ref/CFSAN008157.HGAP.dict    TRUNCATE_NAMES_AT_WHITESPACE=true NUM_SEQUENCES=2147483647 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false\n",
      "[Sun Dec 07 20:58:43 UTC 2014] Executing as root@e107a6ceadc9 on Linux 3.16.4-tinycore64 amd64; OpenJDK 64-Bit Server VM 1.7.0_65-b32; Picard version: 1.111(1901) IntelDeflater\n",
      "[Sun Dec 07 20:58:43 UTC 2014] net.sf.picard.sam.CreateSequenceDictionary done. Elapsed time: 0.00 minutes.\n",
      "Runtime.totalMemory()=31981568\n"
     ]
    }
   ],
   "source": [
    "# code used to create reference dictionary - need to make into function\n",
    "%%bash\n",
    "java -jar ../../usr/local/bin/CreateSequenceDictionary.jar \\\n",
    "    R=../data/RM8375/ref/CFSAN008157.HGAP.fasta \\\n",
    "    O=../data/RM8375/ref/CFSAN008157.HGAP.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 2)",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  },
  "signature": "sha256:e8c94c0adf389320fc61dff95a176706fbbc30e973d397b3cc8d2b28a9c796ff"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}