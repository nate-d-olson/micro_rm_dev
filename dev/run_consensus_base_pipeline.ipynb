{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Whole genome vcf files\n",
    "\n",
    "Input: Individually mapped bam files     \n",
    "Output: Single VCF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import subprocess\n",
    "from bwa_mem_pe import *\n",
    "from consensus_base_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_run_params(run_info,parameters):\n",
    "    # hash for storing run specific information\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    run_params = defaultdict(str)\n",
    "    run_info_list = run_info.split(\":\")\n",
    "    run_params['plat'] = run_info_list[1]\n",
    "    run_params['run_id'] = run_info_list[0]\n",
    "#     run_params['vial'] = run_info_list[2]\n",
    "#     run_params['rep'] = run_info_list[3]\n",
    "    \n",
    "#     fastq_root = parameters['root_dir'] + parameters['fastq_dir'] + \\\n",
    "#                                    run_info_list[1] + '/'+ 'fastq'+'/'\n",
    "#     if run_info_list[1] == \"MiSeq\":\n",
    "#         run_params['fastq1'] = fastq_root + run_info_list[0] + \"_1.fastq\"\n",
    "#         run_params['fastq2'] = fastq_root + run_info_list[0] + \"_2.fastq\"\n",
    "#     else:\n",
    "#         run_params['fastq1'] = fastq_root + run_info_list[0] + \".fastq\"\n",
    "#         run_params['fastq2'] = None\n",
    "        \n",
    "    run_params['out_dir'] = parameters['root_dir'] + parameters['analysis_out_dir']\n",
    "    run_params['log_dir'] = run_params['out_dir'] + \"logs\"\n",
    "#     run_params['sam'] = run_params['out_dir'] + \"/tmp/\" + run_params['run_id'] + \".sam\"\n",
    "    bam_root = parameters['root_dir'] + parameters['analysis_out_dir'] + \"tmp/\" + run_params['run_id']\n",
    "    run_params['bam'] = parameters['root_dir'] + parameters['bam_dir'] + \"/\" + \\\n",
    "                        run_params['run_id'] + \".bam\"\n",
    "    run_params['fix_file'] = bam_root + \"_fix.bam\"\n",
    "    run_params['sort_file'] = bam_root + \"_sort.bam\"\n",
    "    run_params['group_sort_file'] = bam_root + \"_group_sort.bam\"\n",
    "    run_params['realign_file'] = bam_root + \"_realign.bam\"\n",
    "    run_params['intervals_file'] = bam_root + \".intervals\"\n",
    "    run_params['markdup_file'] = bam_root + \"_markdup.bam\"\n",
    "    run_params['metrics_file'] = bam_root + \".metrics\"\n",
    "#     run_params['sorted_bam'] = run_params['out_dir'] + \"/\"+ run_params['run_id'] + \".bam\"\n",
    "#     run_params['read_group'] = \"@RG\\tID:%s\\tCN:%s\\tLB:%s\\tPL:%s\\tSM:%s\" %(run_params['run_id'],\n",
    "#                                                                           parameters['center'],\n",
    "#                                                                           run_params['vial']+\"-\"+run_params['rep'],\n",
    "#                                                                           run_params['plat'],\n",
    "#                                                                           run_params['run_id'])\n",
    "    return run_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dedup_realign_single_bam(bam_params, consensus_params):\n",
    "    ''' Processing single bam file'''\n",
    "    bam_group_sort(in_bam = bam_params['bam'], \n",
    "                   out_bam = bam_params['group_sort_file'], \n",
    "                   log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_fixmate(in_bam = bam_params['group_sort_file'],\n",
    "                out_bam = bam_params['fix_file'],\n",
    "                log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_sort(in_bam = bam_params['fix_file'], \n",
    "            out_sort = bam_params['sort_file'], \n",
    "            out_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_index(bam = bam_params['sort_file'],\n",
    "              out_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_realign(ref = consensus_params['ref'],\n",
    "                in_bam = bam_params['sort_file'],\n",
    "                out_bam = bam_params['realign_file'], \n",
    "                intervals_file = bam_params['intervals_file'],\n",
    "                log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_markdup(in_bam = bam_params['realign_file'], \n",
    "                out_bam = bam_params['markdup_file'], \n",
    "                metrics_file = bam_params['metrics_file'],\n",
    "                log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_index(bam = bam_params['markdup_file'],\n",
    "              out_dir = bam_params['log_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_consensus_base_pipeline(run_params,consensus_params):\n",
    "    \n",
    "    ## creating file with run parameters\n",
    "    run_log_file = open(run_params['out_dir']+\"/\" + run_params['run_id'] +\"-run_parameters.txt\", 'w')\n",
    "    run_log_file.write(\"Parameter\\tValue\\n\")\n",
    "    for i in run_params.keys():\n",
    "        run_log_file.write(\"%s\\t%s\\n\" % (i, run_params[i]))\n",
    "    for i in consensus_params.keys():\n",
    "        run_log_file.write(\"%s\\t%s\\n\" % (i, consensus_params[i]))\n",
    "    run_log_file.close()\n",
    "    \n",
    "    ## processing bam\n",
    "    dedup_realign_single_bam(run_params, consensus_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def genome_pileups(parameters, markdup_files):\n",
    "    \n",
    "    out_dir = parameters['root_dir'] + parameters['analysis_out_dir']\n",
    "    vcf_file = out_dir + \"/\" + \"RM8375-MiSeq.vcf\"\n",
    "    \n",
    "    genome_calls_mpileup(markdup_files['MiSeq'],parameters['ref'],vcf_file,out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dat(filename):\n",
    "    #process input file with configuration information\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    parameters = defaultdict(str)\n",
    "    with open(filename,'r') as f:\n",
    "        for line in f:\n",
    "            param = line.strip().split(\"=\")\n",
    "            parameters[param[0]] = param[1]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(filename):\n",
    "    #read run parameters from input file and process using pathoscope\n",
    "    parameters = read_dat(filename)\n",
    "    \n",
    "    # creating temp and log directories\n",
    "    subprocess.call(['mkdir','-p',parameters['root_dir']+ parameters['analysis_out_dir']+\"/tmp/\"])\n",
    "    subprocess.call(['mkdir','-p',parameters['root_dir']+ parameters['analysis_out_dir']+\"/logs/\"])\n",
    "    \n",
    "    \n",
    "    markdup_files = {'PGM':[], 'MiSeq':[]}\n",
    "\n",
    "    for i in parameters['datasets'].split(\";\"):\n",
    "        run_params = define_run_params(i,parameters)\n",
    "    \n",
    "        markdup_files[run_params['plat']] += run_params['markdup_file']\n",
    "            \n",
    "        run_consensus_base_pipeline(run_params, parameters)\n",
    "        \n",
    "#     genome_pileups(parameters, markdup_files)\n",
    "    \n",
    "    \n",
    "    # merge and process bams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting bam ...\n",
      "Fixing mate pairs ...\n",
      "Realignment Around Indels ...\n",
      "Marking Duplicates ...\n",
      "Sorting bam ...\n",
      "Fixing mate pairs ...\n",
      "Realignment Around Indels ...\n",
      "Marking Duplicates ...\n"
     ]
    }
   ],
   "source": [
    "main(\"consensus_base_params_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* clean up input definitions\n",
    "* need reference dict file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_purity/:\r\n",
      "total 8.0K\r\n",
      "drwxr-xr-x 1 1000 staff 952 Jan 13  2015 \u001b[0m\u001b[01;34mlogs\u001b[0m/\r\n",
      "-rw-r--r-- 1 1000 staff 924 Jan 13  2015 SRR1555296-run_parameters.txt\r\n",
      "-rw-r--r-- 1 1000 staff 924 Jan 13  2015 SRR1555297-run_parameters.txt\r\n",
      "drwxr-xr-x 1 1000 staff 340 Jan 13  2015 \u001b[01;34mtmp\u001b[0m/\r\n",
      "\r\n",
      "sequence_purity/logs:\r\n",
      "total 48K\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_fixmate-2014-12-07-17-42-56.log\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_fixmate-2014-12-07-17-42-56.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_fixmate-2014-12-07-17-46-07.log\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_fixmate-2014-12-07-17-46-07.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_group_sort-2014-12-07-17-41-42.log\r\n",
      "-rw-r--r-- 1 1000 staff   40 Jan 13  2015 bwa_group_sort-2014-12-07-17-41-42.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_group_sort-2014-12-07-17-45-04.log\r\n",
      "-rw-r--r-- 1 1000 staff   40 Jan 13  2015 bwa_group_sort-2014-12-07-17-45-04.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-44-44.log\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-44-44.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-45-04.log\r\n",
      "-rw-r--r-- 1 1000 staff   92 Jan 13  2015 bwa_index-2014-12-07-17-45-04.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-47-39.log\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-47-39.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_index-2014-12-07-17-47-54.log\r\n",
      "-rw-r--r-- 1 1000 staff   92 Jan 13  2015 bwa_index-2014-12-07-17-47-54.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_markdup-2014-12-07-17-45-04.log\r\n",
      "-rw-r--r-- 1 1000 staff 1.6K Jan 13  2015 bwa_markdup-2014-12-07-17-45-04.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_markdup-2014-12-07-17-47-54.log\r\n",
      "-rw-r--r-- 1 1000 staff 1.6K Jan 13  2015 bwa_markdup-2014-12-07-17-47-54.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_realign-2014-12-07-17-44-52.log\r\n",
      "-rw-r--r-- 1 1000 staff 7.1K Jan 13  2015 bwa_realign-2014-12-07-17-44-52.stder\r\n",
      "-rw-r--r-- 1 1000 staff    0 Jan 13  2015 bwa_realign-2014-12-07-17-47-46.log\r\n",
      "-rw-r--r-- 1 1000 staff 7.1K Jan 13  2015 bwa_realign-2014-12-07-17-47-46.stder\r\n",
      "-rw-r--r-- 1 1000 staff   40 Jan 13  2015 bwa_sort-2014-12-07-17-43-44.stder\r\n",
      "-rw-r--r-- 1 1000 staff   40 Jan 13  2015 bwa_sort-2014-12-07-17-46-48.stder\r\n",
      "\r\n",
      "sequence_purity/tmp:\r\n",
      "total 1.4G\r\n",
      "-rw-r--r-- 1 1000 staff 273M Jan 13  2015 SRR1555296_fix.bam\r\n",
      "-rw-r--r-- 1 1000 staff 273M Jan 13  2015 SRR1555296_group_sort.bam\r\n",
      "-rw-r--r-- 1 1000 staff 193M Jan 13  2015 SRR1555296_sort.bam\r\n",
      "-rw-r--r-- 1 1000 staff  17K Jan 13  2015 SRR1555296_sort.bam.bai\r\n",
      "-rw-r--r-- 1 1000 staff 229M Jan 13  2015 SRR1555297_fix.bam\r\n",
      "-rw-r--r-- 1 1000 staff 229M Jan 13  2015 SRR1555297_group_sort.bam\r\n",
      "-rw-r--r-- 1 1000 staff 161M Jan 13  2015 SRR1555297_sort.bam\r\n",
      "-rw-r--r-- 1 1000 staff  17K Jan 13  2015 SRR1555297_sort.bam.bai\r\n"
     ]
    }
   ],
   "source": [
    "ls -lRh sequence_purity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm -r sequence_purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/notebooks/dev'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 2)",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  },
  "signature": "sha256:f1fcba8e28d87a90df5a1116c6edc32b3bb4bcb667a4663a540c2f2963870b75"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}