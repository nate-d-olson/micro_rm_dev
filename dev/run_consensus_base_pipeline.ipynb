{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Whole genome vcf files\n",
    "\n",
    "Input: Individually mapped bam files     \n",
    "Output: Single VCF file\n",
    "\n",
    "TODO:\n",
    "* clean up input definitions\n",
    "* output directory \n",
    "\n",
    "    run_name - root directory\n",
    "    \\tmp - intermediate files\n",
    "    \\run_id\n",
    "        | final bam\n",
    "        \\ logs - log files\n",
    "    \\vcf - platform specific vcf files\n",
    "\n",
    "* need reference dict file - create function, seperate python file with scripts for indexing and creating dict for the reference\n",
    "\n",
    "Reference dict code\n",
    "java -jar ../../usr/local/bin/CreateSequenceDictionary.jar \\\n",
    "    R=../data/RM8375/ref/CFSAN008157.HGAP.fasta \\\n",
    "    O=../data/RM8375/ref/CFSAN008157.HGAP.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import subprocess\n",
    "from bwa_mem_pe import *\n",
    "from consensus_base_pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_run_params(run_info,parameters):\n",
    "    # hash for storing run specific information\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    run_params = defaultdict(str)\n",
    "    run_info_list = run_info.split(\":\")\n",
    "    run_params['plat'] = run_info_list[1]\n",
    "    run_params['run_id'] = run_info_list[0]        \n",
    "    run_params['out_dir'] = parameters['root_dir'] + parameters['analysis_out_dir']\n",
    "    run_params['log_dir'] = run_params['out_dir'] + \"logs\"\n",
    "    bam_root = parameters['root_dir'] + parameters['analysis_out_dir'] + \"tmp/\" + run_params['run_id']\n",
    "    run_params['bam'] = parameters['root_dir'] + parameters['bam_dir'] + \"/\" + run_params['plat'] + \"/\" \\\n",
    "                        run_params['run_id'] + \".bam\"\n",
    "    run_params['fix_file'] = bam_root + \"_fix.bam\"\n",
    "    run_params['sort_file'] = bam_root + \"_sort.bam\"\n",
    "    run_params['group_sort_file'] = bam_root + \"_group_sort.bam\"\n",
    "    run_params['realign_file'] = bam_root + \"_realign.bam\"\n",
    "    run_params['intervals_file'] = bam_root + \".intervals\"\n",
    "    run_params['markdup_file'] = bam_root + \"_markdup.bam\"\n",
    "    run_params['metrics_file'] = bam_root + \".metrics\"\n",
    "    return run_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dedup_realign_single_bam(bam_params, consensus_params):\n",
    "    ''' Processing single bam file'''\n",
    "    bam_group_sort(in_bam = bam_params['bam'], \n",
    "                   out_bam = bam_params['group_sort_file'], \n",
    "                   log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_fixmate(in_bam = bam_params['group_sort_file'],\n",
    "                out_bam = bam_params['fix_file'],\n",
    "                log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_sort(in_bam = bam_params['fix_file'], \n",
    "            out_sort = bam_params['sort_file'], \n",
    "            out_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_index(bam = bam_params['sort_file'],\n",
    "              out_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_realign(ref = consensus_params['ref'],\n",
    "                in_bam = bam_params['sort_file'],\n",
    "                out_bam = bam_params['realign_file'], \n",
    "                intervals_file = bam_params['intervals_file'],\n",
    "                log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_markdup(in_bam = bam_params['realign_file'], \n",
    "                out_bam = bam_params['markdup_file'], \n",
    "                metrics_file = bam_params['metrics_file'],\n",
    "                log_dir = bam_params['log_dir'])\n",
    "    \n",
    "    bam_index(bam = bam_params['markdup_file'],\n",
    "              out_dir = bam_params['log_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_consensus_base_pipeline(run_params,consensus_params):\n",
    "    \n",
    "    ## creating file with run parameters\n",
    "    run_log_file = open(run_params['out_dir']+\"/\" + run_params['run_id'] +\"-run_parameters.txt\", 'w')\n",
    "    run_log_file.write(\"Parameter\\tValue\\n\")\n",
    "    for i in run_params.keys():\n",
    "        run_log_file.write(\"%s\\t%s\\n\" % (i, run_params[i]))\n",
    "    for i in consensus_params.keys():\n",
    "        run_log_file.write(\"%s\\t%s\\n\" % (i, consensus_params[i]))\n",
    "    run_log_file.close()\n",
    "    \n",
    "    ## processing bam\n",
    "    dedup_realign_single_bam(run_params, consensus_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def genome_pileups(parameters, markdup_files):\n",
    "    \n",
    "    for plat in [\"MiSeq\", \"PGM\"]:\n",
    "        out_dir = parameters['root_dir'] + parameters['analysis_out_dir']\n",
    "        vcf = out_dir + \"/\" + parameters['RM'] + \"-\" + plat + \".vcf\"\n",
    "        genome_calls_mpileup(bams=markdup_files[plat],ref=parameters['ref'],vcf_file=vcf,log_dir=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dat(filename):\n",
    "    #process input file with configuration information\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    parameters = defaultdict(str)\n",
    "    with open(filename,'r') as f:\n",
    "        for line in f:\n",
    "            param = line.strip().split(\"=\")\n",
    "            parameters[param[0]] = param[1]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(filename):\n",
    "    #read run parameters from input file and process using pathoscope\n",
    "    parameters = read_dat(filename)\n",
    "    \n",
    "    # creating temp and log directories\n",
    "    subprocess.call(['mkdir','-p',parameters['root_dir']+ parameters['analysis_out_dir']+\"/tmp/\"])\n",
    "    subprocess.call(['mkdir','-p',parameters['root_dir']+ parameters['analysis_out_dir']+\"/logs/\"])\n",
    "    \n",
    "    \n",
    "    # list of refined bams\n",
    "    markdup_files = {'PGM':[], 'MiSeq':[]}\n",
    "    for i in parameters['datasets'].split(\";\"):\n",
    "        run_params = define_run_params(i,parameters)\n",
    "    \n",
    "        markdup_files[run_params['plat']] += [run_params['markdup_file']]\n",
    "            \n",
    "        #run_consensus_base_pipeline(run_params, parameters)\n",
    "       \n",
    "    # pileups by platform\n",
    "    genome_pileups(parameters, markdup_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mpileup ...\n",
      "Running mpileup ...\n"
     ]
    }
   ],
   "source": [
    "main(\"consensus_base_params_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm -r sequence_purity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 2)",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  },
  "signature": "sha256:6c6ad31db09818d83c7e3edc0a5cc9c100134b2d7b17351c0eae3da4b65468ab"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}